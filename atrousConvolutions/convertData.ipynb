{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radlr/anaconda3/envs/cogComMic/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# convert tifs to .npy file \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio as misc # I think this is deprecated, we'll see!\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def getData(myDir,myCurDir):\n",
    "    myStart = 0\n",
    "    for myFile in myCurDir:\n",
    "        myTempImg = misc.imread(myDir+myFile)\n",
    "        if len(myTempImg.shape)==3:\n",
    "            myTempImg = myTempImg[:,:,0]\n",
    "        \n",
    "            \n",
    "        if myStart == 0:\n",
    "            myDimX = np.shape(myTempImg)[0]\n",
    "            myDimY = np.shape(myTempImg)[1]\n",
    "            myData = np.reshape(myTempImg, (1,myDimX, myDimY))\n",
    "            myStart = 1\n",
    "        else:\n",
    "            myData = np.append(myData,np.reshape(myTempImg, (1,myDimX, myDimY)),axis=0)\n",
    "    return myData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function resize_images in module tensorflow.python.ops.image_ops_impl:\n",
      "\n",
      "resize_images(images, size, method=0, align_corners=False)\n",
      "    Resize `images` to `size` using the specified `method`.\n",
      "    \n",
      "    Resized images will be distorted if their original aspect ratio is not\n",
      "    the same as `size`.  To avoid distortions see\n",
      "    @{tf.image.resize_image_with_crop_or_pad}.\n",
      "    \n",
      "    `method` can be one of:\n",
      "    \n",
      "    *   <b>`ResizeMethod.BILINEAR`</b>: [Bilinear interpolation.](\n",
      "      https://en.wikipedia.org/wiki/Bilinear_interpolation)\n",
      "    *   <b>`ResizeMethod.NEAREST_NEIGHBOR`</b>: [Nearest neighbor interpolation.](\n",
      "      https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation)\n",
      "    *   <b>`ResizeMethod.BICUBIC`</b>: [Bicubic interpolation.](\n",
      "      https://en.wikipedia.org/wiki/Bicubic_interpolation)\n",
      "    *   <b>`ResizeMethod.AREA`</b>: Area interpolation.\n",
      "    \n",
      "    The return value has the same type as `images` if `method` is\n",
      "    `ResizeMethod.NEAREST_NEIGHBOR`. It will also have the same type as `images`\n",
      "    if the size of `images` can be statically determined to be the same as `size`,\n",
      "    because `images` is returned in this case. Otherwise, the return value has\n",
      "    type `float32`.\n",
      "    \n",
      "    Args:\n",
      "      images: 4-D Tensor of shape `[batch, height, width, channels]` or\n",
      "              3-D Tensor of shape `[height, width, channels]`.\n",
      "      size: A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The\n",
      "            new size for the images.\n",
      "      method: ResizeMethod.  Defaults to `ResizeMethod.BILINEAR`.\n",
      "      align_corners: bool. If true, exactly align all 4 corners of the input and\n",
      "                     output. Defaults to `false`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: if the shape of `images` is incompatible with the\n",
      "        shape arguments to this function\n",
      "      ValueError: if `size` has invalid shape or type.\n",
      "      ValueError: if an unsupported resize method is specified.\n",
      "    \n",
      "    Returns:\n",
      "      If `images` was 4-D, a 4-D float Tensor of shape\n",
      "      `[batch, new_height, new_width, channels]`.\n",
      "      If `images` was 3-D, a 3-D float Tensor of shape\n",
      "      `[new_height, new_width, channels]`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.image.resize_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 768, 1024) (165, 768, 1024)\n",
      "(1320, 256, 256) (1320, 256, 256)\n",
      "size of training set (1056, 256, 256)\n",
      "size of validation set (264, 256, 256)\n",
      "size of test set (1320, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get a list\n",
    "\"\"\" \n",
    "A. Lucchi Y. Li and P. Fua, Learning for Structured Prediction Using Approximate Subgradient Descent with Working Sets, Conference on Computer Vision and Pattern Recognition, 2013.\n",
    " \n",
    "A. Lucchi, K.Smith, R. Achanta, G. Knott, P. Fua, Supervoxel-Based Segmentation of Mitochondria in EM Image Stacks with Learned Shape Features, IEEE Transactions on Medical Imaging, Vol. 30, Nr. 11, October 2011.\n",
    "\n",
    "https://cvlab.epfl.ch/data/em\"\"\"\n",
    "\n",
    "myDir = \"../datasets/epflEM/imageSequences/testImgs/\"\n",
    "myCurDir = os.listdir(myDir)\n",
    "\n",
    "myData = getData(myDir,myCurDir)\n",
    "myData = tf.images.image_resize(myData,[384,512])\n",
    "\n",
    "myDir = \"../datasets/epflEM/imageSequences/testLabels/\"\n",
    "myCurDir = os.listdir(myDir)\n",
    "\n",
    "myDataLabels = getData(myDir,myCurDir)\n",
    "\n",
    "myData = tf.images.image_resize(myData,[384,512])\n",
    "\n",
    "myDir = \"../datasets/epflEM/imageSequences/trainImgs/\"\n",
    "myCurDir = os.listdir(myDir)\n",
    "\n",
    "myDataX = getData(myDir,myCurDir)\n",
    "\n",
    "myDir = \"../datasets/epflEM/imageSequences/trainLabels/\"\n",
    "myCurDir = os.listdir(myDir)\n",
    "\n",
    "myDataY = getData(myDir,myCurDir)\n",
    "\n",
    "\n",
    "# check if we did it right\n",
    "\n",
    "print(np.shape(myData),np.shape(myDataLabels))\n",
    "\n",
    "# crop images into quarters\n",
    "\n",
    "for cx in range(1):\n",
    "    for cy in range(2):\n",
    "        if(cx == 0 and cy == 0):\n",
    "            X = myDataX[:,0:256,0:256]\n",
    "            Y = myDataY[:,0:256,0:256]\n",
    "            \n",
    "            XTest = myData[:,0:256,0:256]\n",
    "            YTest = myDataLabels[:,0:256,0:256]\n",
    "        else:\n",
    "            X = np.append(X,myDataX[:,cx*256:cx*256+256,cy*256:cy*256+256],axis=0)\n",
    "            Y = np.append(Y,myDataY[:,cx*256:cx*256+256,cy*256:cy*256+256],axis=0)\n",
    "            XTest = np.append(XTest,myData[:,cx*256:cx*256+256,cy*256:cy*256+256],axis=0)\n",
    "            YTest = np.append(YTest,myDataLabels[:,cx*256:cx*256+256,cy*256:cy*256+256],axis=0)\n",
    "print(X.shape,Y.shape) \n",
    "\n",
    "# shuffle data\n",
    "np.random.seed(13)\n",
    "np.random.shuffle(X)\n",
    "\n",
    "np.random.seed(13)\n",
    "np.random.shuffle(Y)\n",
    "\n",
    "# set aside 10% for validation dataset\n",
    "noVal = int(0.2*len(X))\n",
    "XVal = X[0:noVal,:,:]\n",
    "YVal = Y[0:noVal,:,:]\n",
    "\n",
    "X = X[noVal:len(X),:,:]\n",
    "Y = Y[noVal:len(X),:,:]\n",
    "print(\"size of training set\",X.shape)\n",
    "print(\"size of validation set\",XVal.shape)\n",
    "print(\"size of test set\",XTest.shape)\n",
    "if(1):\n",
    "    #Save data and labels in npy format\n",
    "    np.save(\"../datasets/epflEM/epflTestX.npy\",XTest)\n",
    "    np.save(\"../datasets/epflEM/epflTestY.npy\",YTest)\n",
    "    np.save(\"../datasets/epflEM/epflXVal.npy\",XVal)\n",
    "    np.save(\"../datasets/epflEM/epflYVal.npy\",YVal)\n",
    "    np.save(\"../datasets/epflEM/epflXVal.npy\",XVal)\n",
    "    np.save(\"../datasets/epflEM/epflYVal.npy\",YVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 512, 512) (30, 512, 512)\n",
      "(120, 256, 256) (120, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get a list\n",
    "\"\"\"    Albert Cardona, Stephan Saalfeld, Stephan Preibisch, Benjamin Schmid, \n",
    "Anchi Cheng, Jim Pulokas, Pavel Tomancak and Volker Hartenstein (10, 2010), \n",
    "\"An Integrated Micro- and Macroarchitectural Analysis of the Drosophila Brain \n",
    "by Computer-Assisted Serial Section Electron Microscopy\", PLoS Biol \n",
    "(Public Library of Science) 8 (10): e1000502, doi:10.1371/journal.pbio.1000502\n",
    "http://brainiac2.mit.edu/isbi_challenge/home\"\"\"\n",
    "\n",
    "myDir = \"../datasets/isbiEM/imageSequences/trainImgs/\"\n",
    "myCurDir = os.listdir(myDir)\n",
    "\n",
    "myData = getData(myDir,myCurDir)\n",
    "\n",
    "myDir = \"../datasets/isbiEM/imageSequences/trainLabels/\"\n",
    "myCurDir = os.listdir(myDir)\n",
    "\n",
    "\n",
    "myDataLabels = getData(myDir,myCurDir)\n",
    "\n",
    "# check if we did it right\n",
    "\n",
    "print(np.shape(myData),np.shape(myDataLabels))\n",
    "\n",
    "# crop images into quarters\n",
    "\n",
    "for cx in range(2):\n",
    "    for cy in range(2):\n",
    "        if(cx == 0 and cy == 0):\n",
    "            X = myData[:,0:256,0:256]\n",
    "            Y = myDataLabels[:,0:256,0:256]\n",
    "        else:\n",
    "            X = np.append(X,myData[:,cx*256:cx*256+256,cy*256:cy*256+256],axis=0)\n",
    "            Y = np.append(Y,myDataLabels[:,cx*256:cx*256+256,cy*256:cy*256+256],axis=0)\n",
    "print(X.shape,Y.shape) \n",
    "\n",
    "# shuffle data\n",
    "np.random.seed(13)\n",
    "np.random.shuffle(X)\n",
    "\n",
    "np.random.seed(13)\n",
    "np.random.shuffle(Y)\n",
    "\n",
    "# set aside 10% for validation dataset\n",
    "\n",
    "XVal = X[0:12,:,:]\n",
    "YVal = Y[0:12,:,:]\n",
    "\n",
    "X = X[12:len(X),:,:]\n",
    "Y = Y[12:len(X),:,:]\n",
    "\n",
    "if(1):\n",
    "    #Save data and labels in npy format\n",
    "    np.save(\"../datasets/isbiEM/isbiX.npy\",X)\n",
    "    np.save(\"../datasets/isbiEM/isbiY.npy\",Y)\n",
    "    np.save(\"../datasets/isbiEM/isbiXVal.npy\",XVal)\n",
    "    np.save(\"../datasets/isbiEM/isbiYVal.npy\",YVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# get a list\n",
    "\"\"\"data from Coelho, Shariff, and Murphy. 'NUCLEAR SEGMENTATION IN MICROSCOPE CELL IMAGES: \n",
    "A HAND-SEGMENTED DATASET AND COMPARISON OF ALGORITHMS' IEEE (2009)\"\"\"\n",
    "myDir = \"../datasets/coelhoMurphy2009/images/dna-images/gnf/\"\n",
    "myCurDir = os.listdir(myDir)\n",
    "\n",
    "myData1 = getData(myDir,myCurDir)\n",
    "\n",
    "myDir = \"../datasets/coelhoMurphy2009/images/dna-images/ic100/\"\n",
    "myCurDir = os.listdir(myDir)\n",
    "\n",
    "\n",
    "myData2 = getData(myDir,myCurDir)\n",
    "\n",
    "# check if we did it right\n",
    "\n",
    "\n",
    "# combine the two datasets\n",
    "myData = np.append(myData1[:,0:1024,0:1344],myData2[:,0:1024,0:1344],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "1 0\n",
      "1 1\n",
      "(400, 512, 672)\n"
     ]
    }
   ],
   "source": [
    "for cx in range(2):\n",
    "    for cy in range(2):\n",
    "        print(cx,cy)\n",
    "        if (cx==0 and cy==0):\n",
    "            myDataX = myData[:,0:512,0:672]\n",
    "        else:\n",
    "            myDataX = np.append(myDataX,myData[:,cx:512+cx,cy:cy+672],axis=0)\n",
    "print(myDataX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data\n",
    "\n",
    "np.save(\"./coelhoData2.npy\",myDataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 512, 672)\n",
      "(320, 512, 672)\n",
      "(40, 512, 672)\n",
      "(39, 512, 672)\n"
     ]
    }
   ],
   "source": [
    "myData = myDataX\n",
    "print(np.shape(myData))\n",
    "mySeed = 42\n",
    "np.random.seed(mySeed)\n",
    "nVal = int(0.1*len(myData))\n",
    "nTrain = int(0.8*len(myData))\n",
    "\n",
    "np.random.shuffle(myData)\n",
    "\n",
    "myTrain = myData[0:nTrain,:,:]\n",
    "myVal = myData[nTrain:nTrain+nVal,:,:]\n",
    "myTest = myData[nTrain+nVal:len(myData)-1,:,:]\n",
    "\n",
    "\n",
    "print(np.shape(myTrain))\n",
    "\n",
    "print(np.shape(myVal))\n",
    "\n",
    "print(np.shape(myTest))\n",
    "np.save(\"./coelTrain2.npy\",myTrain)\n",
    "np.save(\"./coelVal2.npy\",myVal)\n",
    "np.save(\"./coelTest2.npy\",myTest)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3Thesis Cog. Com. Mic.",
   "language": "python",
   "name": "cocommic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
